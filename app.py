# app.py â€“ Fixed CSV parsing & skillâ€‘match logic
import streamlit as st
import pandas as pd
import re, io, requests
from PIL import Image
import pytesseract
import fitz  # PyMuPDF
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

st.set_page_config(page_title="College Smart Placement Advisor", page_icon="ğŸ“")
st.title("ğŸ“ College Smart Placement Advisor")
st.write("Upload à¤…à¤ªà¤¨à¤¾ **Resume (PDF / Image / Drive link)** à¤¯à¤¾ form à¤­à¤° à¤•à¤° personalised career advice à¤ªà¤¾à¤“!")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1.  Load job_roles.csv (quotesâ€‘safe)
roles_df = pd.read_csv("job_roles.csv")
# master skills set
MASTER_SKILLS = {s.lower() for skills in roles_df["Required_Skills"] for s in skills.split(",")}

def extract_skills(text: str) -> str:
    words = {w.lower() for w in re.findall(r"[A-Za-z+#\.]+", text)}
    return ", ".join(sorted(words & MASTER_SKILLS))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2.  Resume Input
st.subheader("ğŸ“„ Resume Input")
c1, c2 = st.columns(2)
with c1:
    pdf_file = st.file_uploader("Upload PDF / Image", type=["pdf", "png", "jpg", "jpeg"])
with c2:
    pdf_url = st.text_input("â€¦or paste Google Drive link")

resume_text = ""

def read_pdf_bytes(pdf_bytes):
    text = ""
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text

if pdf_file:
    if pdf_file.type == "application/pdf":
        resume_text = read_pdf_bytes(pdf_file.read())
    else:
        resume_text = pytesseract.image_to_string(Image.open(pdf_file))
elif pdf_url:
    if "drive.google.com" in pdf_url:
        m = re.search(r"/d/([A-Za-z0-9_-]+)", pdf_url)
        if m:
            pdf_url = f"https://drive.google.com/uc?id={m.group(1)}"
    if st.button("Fetch PDF"):
        try:
            resume_text = read_pdf_bytes(requests.get(pdf_url).content)
            st.success("âœ… Resume fetched!")
        except Exception as e:
            st.error(f"âŒ {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3.  Autoâ€‘extract Name / CGPA / Certs
auto_name = auto_cgpa = auto_certs = ""
if resume_text:
    for line in resume_text.splitlines():
        if line.strip():
            auto_name = " ".join(line.strip().split()[:2]).title()
            break
    cg = re.search(r"(\d\.\d{1,2})\s*/\s*10|CGPA", resume_text, re.I)
    pc = re.search(r"(\d{2,3})\s*%", resume_text)
    if cg:
        auto_cgpa = float(cg.group(1))
    elif pc:
        auto_cgpa = round(float(pc.group(1)) / 9.5, 2)
    CERT_KEYS = ["aws", "cisco", "coursera", "isro", "google"]
    auto_certs = ", ".join([k.upper() for k in CERT_KEYS if k in resume_text.lower()])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4.  Form
st.subheader("ğŸ“ Quick Profile Form")
with st.form("user_form"):
    name   = st.text_input("Name", value=auto_name)
    cgpa   = st.number_input("CGPA (0â€“10)", min_value=0.0, max_value=10.0, step=0.1, value=float(auto_cgpa) if auto_cgpa else 0.0)
    skills = st.text_area("Skills (commaâ€‘sep)", value=extract_skills(resume_text) if resume_text else "")
    certs  = st.text_area("Certifications", value=auto_certs)
    projs  = st.text_area("Projects")
    submit = st.form_submit_button("ğŸ” Get Recommendation")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5.  Recommendation
if submit:
    if not skills.strip():
        st.error("âš ï¸  Skills blank hain, manually add karo.")
        st.stop()

    profile_doc = ", ".join([skills, certs, projs]).lower()
    docs  = [profile_doc] + roles_df["Required_Skills"].str.lower().tolist()
    vecs  = TfidfVectorizer().fit_transform(docs)
    sims  = cosine_similarity(vecs[0:1], vecs[1:]).flatten()
    roles_df["Match %"] = (sims * 100).round(2)
    top3 = roles_df.sort_values("Match %", ascending=False).head(3)

    st.subheader("ğŸ“Š Recommended Roles")
    for _, r in top3.iterrows():
        st.markdown(f"**{r['Role']}** â€” {r['Match %']} % match")

    # skill suggestions for best role
    best = top3.iloc[0]
    role_skills = [s.strip().lower() for s in best["Required_Skills"].split(",")]
    user_skills = [s.strip().lower() for s in skills.split(",")]
    missing = [sk for sk in role_skills if sk not in user_skills]

    st.subheader("ğŸ§  Skill Suggestions")
    if missing:
        st.markdown("à¤‡à¤¨ skills à¤ªà¤° à¤•à¤¾à¤® à¤•à¤°à¥‹:")
        st.markdown("\n".join(f"- {m.title()}" for m in missing))
    else:
        st.success("âœ… à¤¤à¥‚ already ready à¤¹à¥ˆ!")

    # bar chart
    st.subheader("ğŸ“ˆ Role-wise Match %")
    fig, ax = plt.subplots()
    ax.bar(roles_df["Role"], roles_df["Match %"])
    ax.set_ylim(0, 100)
    ax.set_ylabel("Match %")
    ax.set_xticklabels(roles_df["Role"], rotation=12)
    st.pyplot(fig)

    st.info("ğŸ’¡ Missing skills à¤•à¥‹ à¤¸à¥€à¤– à¤•à¤° progress track à¤•à¤°!")

